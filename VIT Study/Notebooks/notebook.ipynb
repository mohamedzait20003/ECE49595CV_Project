{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "682299ec",
   "metadata": {},
   "source": [
    "# Vision Transformer Training for Car Classification\n",
    "\n",
    "This notebook trains a Vision Transformer (ViT) model for multi-label car classification:\n",
    "- **Brand** classification (e.g., BMW, Audi, Toyota)\n",
    "- **Model** classification (e.g., M3, A4, Camry)\n",
    "- **Year** classification (e.g., 2000, 2010, 2020)\n",
    "\n",
    "The model uses the Stanford Cars196 dataset with a three-headed classifier architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76ccc94",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6472c1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Setup project paths\n",
    "project_root = Path(os.getcwd()).parent\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Import custom modules\n",
    "from Model.Model import VisionTransformer, create_vit_base\n",
    "from Utilities.Cars196 import create_dataloaders\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "    print(f\"Available GPUs: {torch.cuda.device_count()}\")\n",
    "else:\n",
    "    print(\"No GPU available - using CPU\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14873c84",
   "metadata": {},
   "source": [
    "## 2. Setup Directories and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cac1df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create necessary directories\n",
    "project_root = Path(os.getcwd()).parent\n",
    "cache_dir = project_root / 'cache'\n",
    "checkpoint_dir = project_root / 'checkpoints'\n",
    "results_dir = project_root / 'results'\n",
    "\n",
    "# Create directories\n",
    "cache_dir.mkdir(exist_ok=True)\n",
    "checkpoint_dir.mkdir(exist_ok=True)\n",
    "results_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"Directory Setup:\")\n",
    "print(f\"  Project Root: {project_root}\")\n",
    "print(f\"  Cache:        {cache_dir}\")\n",
    "print(f\"  Checkpoints:  {checkpoint_dir}\")\n",
    "print(f\"  Results:      {results_dir}\")\n",
    "\n",
    "# Training configuration\n",
    "config = {\n",
    "    'batch_size': 32,\n",
    "    'img_size': 224,\n",
    "    'num_workers': 4,\n",
    "    'learning_rate': 1e-4,\n",
    "    'weight_decay': 1e-4,\n",
    "    'num_epochs': 50,\n",
    "    'patience': 10,  # Early stopping patience\n",
    "    'save_frequency': 5,  # Save checkpoint every N epochs\n",
    "    \n",
    "    # Model configuration\n",
    "    'embed_dim': 768,\n",
    "    'depth': 12,\n",
    "    'num_heads': 12,\n",
    "    'mlp_ratio': 4.0,\n",
    "    'dropout': 0.1,\n",
    "}\n",
    "\n",
    "print(\"\\nTraining Configuration:\")\n",
    "print(json.dumps(config, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69955d2",
   "metadata": {},
   "source": [
    "## 3. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793b02ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloaders with caching\n",
    "print(\"Loading Cars196 dataset...\")\n",
    "train_loader, test_loader = create_dataloaders(\n",
    "    root_dir=None,  # Auto-download if not present\n",
    "    batch_size=config['batch_size'],\n",
    "    img_size=config['img_size'],\n",
    "    num_workers=config['num_workers'],\n",
    "    auto_download=True,\n",
    "    cache_dir=str(cache_dir)\n",
    ")\n",
    "\n",
    "# Get dataset information\n",
    "train_dataset = train_loader.dataset\n",
    "test_dataset = test_loader.dataset\n",
    "num_classes = train_dataset.get_num_classes()\n",
    "\n",
    "print(f\"\\nDataset Statistics:\")\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")\n",
    "print(f\"Number of brands: {num_classes['brand']}\")\n",
    "print(f\"Number of models: {num_classes['model']}\")\n",
    "print(f\"Number of years: {num_classes['year']}\")\n",
    "print(f\"Total classes: {num_classes['total']}\")\n",
    "\n",
    "# Visualize a sample batch\n",
    "sample_images, sample_labels = next(iter(train_loader))\n",
    "print(f\"\\nBatch shape: {sample_images.shape}\")\n",
    "print(f\"Sample brand indices: {sample_labels['brand'][:5].tolist()}\")\n",
    "print(f\"Sample brand names: {sample_labels['brand_name'][:5]}\")\n",
    "print(f\"Sample model names: {sample_labels['model_name'][:5]}\")\n",
    "print(f\"Sample years: {sample_labels['year_value'][:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1949349a",
   "metadata": {},
   "source": [
    "## 4. Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf9fd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Vision Transformer model\n",
    "model = create_vit_base(\n",
    "    num_classes_brand=num_classes['brand'],\n",
    "    num_classes_model=num_classes['model'],\n",
    "    num_classes_year=num_classes['year'],\n",
    "    img_size=config['img_size'],\n",
    "    embed_dim=config['embed_dim'],\n",
    "    depth=config['depth'],\n",
    "    num_heads=config['num_heads'],\n",
    "    mlp_ratio=config['mlp_ratio'],\n",
    "    dropout=config['dropout']\n",
    ")\n",
    "\n",
    "# Move model to device\n",
    "model = model.to(device)\n",
    "\n",
    "# Print model information\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(\"Model Architecture:\")\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"Model size: {total_params * 4 / 1024**2:.2f} MB (float32)\")\n",
    "\n",
    "# Test forward pass\n",
    "with torch.no_grad():\n",
    "    test_input = torch.randn(2, 3, config['img_size'], config['img_size']).to(device)\n",
    "    brand_out, model_out, year_out = model(test_input)\n",
    "    print(f\"\\nOutput shapes:\")\n",
    "    print(f\"Brand: {brand_out.shape}\")\n",
    "    print(f\"Model: {model_out.shape}\")\n",
    "    print(f\"Year: {year_out.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377e8e89",
   "metadata": {},
   "source": [
    "## 5. Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47e5580",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, criterion, optimizer, device, epoch):\n",
    "    \"\"\"\n",
    "    Train the model for one epoch.\n",
    "    \n",
    "    Args:\n",
    "        model: Vision Transformer model\n",
    "        dataloader: Training dataloader\n",
    "        criterion: Loss function\n",
    "        optimizer: Optimizer\n",
    "        device: Device to train on\n",
    "        epoch: Current epoch number\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing average losses and accuracies\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    \n",
    "    total_loss = 0\n",
    "    brand_loss_sum = 0\n",
    "    model_loss_sum = 0\n",
    "    year_loss_sum = 0\n",
    "    \n",
    "    brand_correct = 0\n",
    "    model_correct = 0\n",
    "    year_correct = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    progress_bar = tqdm(dataloader, desc=f'Epoch {epoch}')\n",
    "    \n",
    "    for batch_idx, (images, labels) in enumerate(progress_bar):\n",
    "        images = images.to(device)\n",
    "        brand_labels = labels['brand'].to(device)\n",
    "        model_labels = labels['model'].to(device)\n",
    "        year_labels = labels['year'].to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        brand_out, model_out, year_out = model(images)\n",
    "        \n",
    "        # Compute losses\n",
    "        brand_loss = criterion(brand_out, brand_labels)\n",
    "        model_loss = criterion(model_out, model_labels)\n",
    "        year_loss = criterion(year_out, year_labels)\n",
    "        \n",
    "        # Combined loss (weighted equally)\n",
    "        loss = brand_loss + model_loss + year_loss\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Calculate accuracies\n",
    "        brand_pred = brand_out.argmax(dim=1)\n",
    "        model_pred = model_out.argmax(dim=1)\n",
    "        year_pred = year_out.argmax(dim=1)\n",
    "        \n",
    "        brand_correct += (brand_pred == brand_labels).sum().item()\n",
    "        model_correct += (model_pred == model_labels).sum().item()\n",
    "        year_correct += (year_pred == year_labels).sum().item()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        brand_loss_sum += brand_loss.item()\n",
    "        model_loss_sum += model_loss.item()\n",
    "        year_loss_sum += year_loss.item()\n",
    "        total_samples += images.size(0)\n",
    "        \n",
    "        # Update progress bar\n",
    "        progress_bar.set_postfix({\n",
    "            'loss': f'{loss.item():.4f}',\n",
    "            'brand_acc': f'{100 * brand_correct / total_samples:.2f}%',\n",
    "            'model_acc': f'{100 * model_correct / total_samples:.2f}%',\n",
    "            'year_acc': f'{100 * year_correct / total_samples:.2f}%'\n",
    "        })\n",
    "    \n",
    "    num_batches = len(dataloader)\n",
    "    \n",
    "    return {\n",
    "        'total_loss': total_loss / num_batches,\n",
    "        'brand_loss': brand_loss_sum / num_batches,\n",
    "        'model_loss': model_loss_sum / num_batches,\n",
    "        'year_loss': year_loss_sum / num_batches,\n",
    "        'brand_accuracy': 100 * brand_correct / total_samples,\n",
    "        'model_accuracy': 100 * model_correct / total_samples,\n",
    "        'year_accuracy': 100 * year_correct / total_samples,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de03763",
   "metadata": {},
   "source": [
    "## 6. Testing/Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42f40d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, criterion, device, split='Test'):\n",
    "    \"\"\"\n",
    "    Evaluate the model on a dataset.\n",
    "    \n",
    "    Args:\n",
    "        model: Vision Transformer model\n",
    "        dataloader: Evaluation dataloader\n",
    "        criterion: Loss function\n",
    "        device: Device to evaluate on\n",
    "        split: Name of the split (for logging)\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing average losses and accuracies\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    total_loss = 0\n",
    "    brand_loss_sum = 0\n",
    "    model_loss_sum = 0\n",
    "    year_loss_sum = 0\n",
    "    \n",
    "    brand_correct = 0\n",
    "    model_correct = 0\n",
    "    year_correct = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    # For computing top-5 accuracy\n",
    "    brand_top5_correct = 0\n",
    "    model_top5_correct = 0\n",
    "    \n",
    "    all_brand_preds = []\n",
    "    all_model_preds = []\n",
    "    all_year_preds = []\n",
    "    all_brand_labels = []\n",
    "    all_model_labels = []\n",
    "    all_year_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        progress_bar = tqdm(dataloader, desc=f'{split} Evaluation')\n",
    "        \n",
    "        for images, labels in progress_bar:\n",
    "            images = images.to(device)\n",
    "            brand_labels = labels['brand'].to(device)\n",
    "            model_labels = labels['model'].to(device)\n",
    "            year_labels = labels['year'].to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            brand_out, model_out, year_out = model(images)\n",
    "            \n",
    "            # Compute losses\n",
    "            brand_loss = criterion(brand_out, brand_labels)\n",
    "            model_loss = criterion(model_out, model_labels)\n",
    "            year_loss = criterion(year_out, year_labels)\n",
    "            loss = brand_loss + model_loss + year_loss\n",
    "            \n",
    "            # Calculate accuracies\n",
    "            brand_pred = brand_out.argmax(dim=1)\n",
    "            model_pred = model_out.argmax(dim=1)\n",
    "            year_pred = year_out.argmax(dim=1)\n",
    "            \n",
    "            brand_correct += (brand_pred == brand_labels).sum().item()\n",
    "            model_correct += (model_pred == model_labels).sum().item()\n",
    "            year_correct += (year_pred == year_labels).sum().item()\n",
    "            \n",
    "            # Top-5 accuracy\n",
    "            _, brand_top5 = brand_out.topk(5, dim=1)\n",
    "            _, model_top5 = model_out.topk(5, dim=1)\n",
    "            \n",
    "            brand_top5_correct += sum([1 for i, label in enumerate(brand_labels) \n",
    "                                       if label in brand_top5[i]])\n",
    "            model_top5_correct += sum([1 for i, label in enumerate(model_labels) \n",
    "                                       if label in model_top5[i]])\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            brand_loss_sum += brand_loss.item()\n",
    "            model_loss_sum += model_loss.item()\n",
    "            year_loss_sum += year_loss.item()\n",
    "            total_samples += images.size(0)\n",
    "            \n",
    "            # Store predictions for confusion matrix\n",
    "            all_brand_preds.extend(brand_pred.cpu().numpy())\n",
    "            all_model_preds.extend(model_pred.cpu().numpy())\n",
    "            all_year_preds.extend(year_pred.cpu().numpy())\n",
    "            all_brand_labels.extend(brand_labels.cpu().numpy())\n",
    "            all_model_labels.extend(model_labels.cpu().numpy())\n",
    "            all_year_labels.extend(year_labels.cpu().numpy())\n",
    "    \n",
    "    num_batches = len(dataloader)\n",
    "    \n",
    "    results = {\n",
    "        'total_loss': total_loss / num_batches,\n",
    "        'brand_loss': brand_loss_sum / num_batches,\n",
    "        'model_loss': model_loss_sum / num_batches,\n",
    "        'year_loss': year_loss_sum / num_batches,\n",
    "        'brand_accuracy': 100 * brand_correct / total_samples,\n",
    "        'model_accuracy': 100 * model_correct / total_samples,\n",
    "        'year_accuracy': 100 * year_correct / total_samples,\n",
    "        'brand_top5_accuracy': 100 * brand_top5_correct / total_samples,\n",
    "        'model_top5_accuracy': 100 * model_top5_correct / total_samples,\n",
    "        'predictions': {\n",
    "            'brand': all_brand_preds,\n",
    "            'model': all_model_preds,\n",
    "            'year': all_year_preds,\n",
    "        },\n",
    "        'labels': {\n",
    "            'brand': all_brand_labels,\n",
    "            'model': all_model_labels,\n",
    "            'year': all_year_labels,\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf1e908",
   "metadata": {},
   "source": [
    "## 7. Training Loop with Checkpointing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f85bf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, test_loader, config, device, \n",
    "                checkpoint_dir, results_dir):\n",
    "    \"\"\"\n",
    "    Complete training loop with validation and checkpointing.\n",
    "    \n",
    "    Args:\n",
    "        model: Vision Transformer model\n",
    "        train_loader: Training dataloader\n",
    "        test_loader: Test dataloader\n",
    "        config: Training configuration dictionary\n",
    "        device: Device to train on\n",
    "        checkpoint_dir: Directory to save checkpoints\n",
    "        results_dir: Directory to save results\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing training history\n",
    "    \"\"\"\n",
    "    # Loss and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=config['learning_rate'],\n",
    "        weight_decay=config['weight_decay']\n",
    "    )\n",
    "    \n",
    "    # Learning rate scheduler\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.5, patience=5\n",
    "    )\n",
    "    \n",
    "    # Training history\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'train_brand_acc': [],\n",
    "        'train_model_acc': [],\n",
    "        'train_year_acc': [],\n",
    "        'test_loss': [],\n",
    "        'test_brand_acc': [],\n",
    "        'test_model_acc': [],\n",
    "        'test_year_acc': [],\n",
    "        'learning_rates': []\n",
    "    }\n",
    "    \n",
    "    best_test_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"Starting Training\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    for epoch in range(1, config['num_epochs'] + 1):\n",
    "        print(f\"\\nEpoch {epoch}/{config['num_epochs']}\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        # Train\n",
    "        train_metrics = train_epoch(\n",
    "            model, train_loader, criterion, optimizer, device, epoch\n",
    "        )\n",
    "        \n",
    "        # Evaluate\n",
    "        test_metrics = evaluate(\n",
    "            model, test_loader, criterion, device, split='Test'\n",
    "        )\n",
    "        \n",
    "        # Update learning rate\n",
    "        current_lr_before = optimizer.param_groups[0]['lr']\n",
    "        scheduler.step(test_metrics['total_loss'])\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        \n",
    "        # Print if learning rate changed\n",
    "        if current_lr != current_lr_before:\n",
    "            print(f\"\\nLearning rate reduced: {current_lr_before:.6f} -> {current_lr:.6f}\")\n",
    "        \n",
    "        # Store history\n",
    "        history['train_loss'].append(train_metrics['total_loss'])\n",
    "        history['train_brand_acc'].append(train_metrics['brand_accuracy'])\n",
    "        history['train_model_acc'].append(train_metrics['model_accuracy'])\n",
    "        history['train_year_acc'].append(train_metrics['year_accuracy'])\n",
    "        history['test_loss'].append(test_metrics['total_loss'])\n",
    "        history['test_brand_acc'].append(test_metrics['brand_accuracy'])\n",
    "        history['test_model_acc'].append(test_metrics['model_accuracy'])\n",
    "        history['test_year_acc'].append(test_metrics['year_accuracy'])\n",
    "        history['learning_rates'].append(current_lr)\n",
    "        \n",
    "        # Print epoch summary\n",
    "        print(f\"\\nEpoch {epoch} Summary:\")\n",
    "        print(f\"  Train Loss: {train_metrics['total_loss']:.4f}\")\n",
    "        print(f\"  Train Brand Acc: {train_metrics['brand_accuracy']:.2f}%\")\n",
    "        print(f\"  Train Model Acc: {train_metrics['model_accuracy']:.2f}%\")\n",
    "        print(f\"  Train Year Acc: {train_metrics['year_accuracy']:.2f}%\")\n",
    "        print(f\"\\n  Test Loss: {test_metrics['total_loss']:.4f}\")\n",
    "        print(f\"  Test Brand Acc: {test_metrics['brand_accuracy']:.2f}%\")\n",
    "        print(f\"  Test Model Acc: {test_metrics['model_accuracy']:.2f}%\")\n",
    "        print(f\"  Test Year Acc: {test_metrics['year_accuracy']:.2f}%\")\n",
    "        print(f\"  Test Brand Top-5 Acc: {test_metrics['brand_top5_accuracy']:.2f}%\")\n",
    "        print(f\"  Test Model Top-5 Acc: {test_metrics['model_top5_accuracy']:.2f}%\")\n",
    "        print(f\"\\n  Learning Rate: {current_lr:.6f}\")\n",
    "        \n",
    "        # Save checkpoint\n",
    "        if epoch % config['save_frequency'] == 0:\n",
    "            checkpoint_path = checkpoint_dir / f'checkpoint_epoch_{epoch}.pth'\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scheduler_state_dict': scheduler.state_dict(),\n",
    "                'train_metrics': train_metrics,\n",
    "                'test_metrics': test_metrics,\n",
    "                'history': history,\n",
    "                'config': config\n",
    "            }, checkpoint_path)\n",
    "            print(f\"\\n  Checkpoint saved: {checkpoint_path.name}\")\n",
    "        \n",
    "        # Save best model\n",
    "        if test_metrics['total_loss'] < best_test_loss:\n",
    "            best_test_loss = test_metrics['total_loss']\n",
    "            patience_counter = 0\n",
    "            \n",
    "            best_model_path = checkpoint_dir / 'best_model.pth'\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'test_metrics': test_metrics,\n",
    "                'config': config\n",
    "            }, best_model_path)\n",
    "            print(f\"  ✓ Best model saved (loss: {best_test_loss:.4f})\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"  No improvement. Patience: {patience_counter}/{config['patience']}\")\n",
    "        \n",
    "        # Early stopping\n",
    "        if patience_counter >= config['patience']:\n",
    "            print(f\"\\nEarly stopping triggered after {epoch} epochs\")\n",
    "            break\n",
    "    \n",
    "    # Save final model\n",
    "    final_model_path = checkpoint_dir / 'final_model.pth'\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'history': history,\n",
    "        'config': config\n",
    "    }, final_model_path)\n",
    "    \n",
    "    # Save training history\n",
    "    history_path = results_dir / 'training_history.json'\n",
    "    with open(history_path, 'w') as f:\n",
    "        json.dump(history, f, indent=2)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"Training Complete!\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Best test loss: {best_test_loss:.4f}\")\n",
    "    print(f\"Final model saved: {final_model_path}\")\n",
    "    print(f\"Training history saved: {history_path}\")\n",
    "    \n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fb9e43",
   "metadata": {},
   "source": [
    "## 8. Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813b9677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    test_loader=test_loader,\n",
    "    config=config,\n",
    "    device=device,\n",
    "    checkpoint_dir=checkpoint_dir,\n",
    "    results_dir=results_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e17994",
   "metadata": {},
   "source": [
    "## 9. Visualize Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6053b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "epochs = range(1, len(history['train_loss']) + 1)\n",
    "\n",
    "# Loss plot\n",
    "axes[0, 0].plot(epochs, history['train_loss'], 'b-', label='Train Loss', linewidth=2)\n",
    "axes[0, 0].plot(epochs, history['test_loss'], 'r-', label='Test Loss', linewidth=2)\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].set_title('Training and Test Loss')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Brand accuracy\n",
    "axes[0, 1].plot(epochs, history['train_brand_acc'], 'b-', label='Train', linewidth=2)\n",
    "axes[0, 1].plot(epochs, history['test_brand_acc'], 'r-', label='Test', linewidth=2)\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Accuracy (%)')\n",
    "axes[0, 1].set_title('Brand Classification Accuracy')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Model accuracy\n",
    "axes[1, 0].plot(epochs, history['train_model_acc'], 'b-', label='Train', linewidth=2)\n",
    "axes[1, 0].plot(epochs, history['test_model_acc'], 'r-', label='Test', linewidth=2)\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('Accuracy (%)')\n",
    "axes[1, 0].set_title('Model Classification Accuracy')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Year accuracy\n",
    "axes[1, 1].plot(epochs, history['train_year_acc'], 'b-', label='Train', linewidth=2)\n",
    "axes[1, 1].plot(epochs, history['test_year_acc'], 'r-', label='Test', linewidth=2)\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "axes[1, 1].set_ylabel('Accuracy (%)')\n",
    "axes[1, 1].set_title('Year Classification Accuracy')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(results_dir / 'training_curves.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nTraining curves saved to: {results_dir / 'training_curves.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912f20b6",
   "metadata": {},
   "source": [
    "## 10. Final Evaluation on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781c7813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "best_model_path = checkpoint_dir / 'best_model.pth'\n",
    "checkpoint = torch.load(best_model_path)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "print(f\"Loaded best model from epoch {checkpoint['epoch']}\")\n",
    "\n",
    "# Evaluate on test set\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "final_results = evaluate(model, test_loader, criterion, device, split='Final Test')\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL TEST SET RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nOverall Test Loss: {final_results['total_loss']:.4f}\")\n",
    "print(f\"\\nBrand Classification:\")\n",
    "print(f\"  Top-1 Accuracy: {final_results['brand_accuracy']:.2f}%\")\n",
    "print(f\"  Top-5 Accuracy: {final_results['brand_top5_accuracy']:.2f}%\")\n",
    "print(f\"  Loss: {final_results['brand_loss']:.4f}\")\n",
    "\n",
    "print(f\"\\nModel Classification:\")\n",
    "print(f\"  Top-1 Accuracy: {final_results['model_accuracy']:.2f}%\")\n",
    "print(f\"  Top-5 Accuracy: {final_results['model_top5_accuracy']:.2f}%\")\n",
    "print(f\"  Loss: {final_results['model_loss']:.4f}\")\n",
    "\n",
    "print(f\"\\nYear Classification:\")\n",
    "print(f\"  Accuracy: {final_results['year_accuracy']:.2f}%\")\n",
    "print(f\"  Loss: {final_results['year_loss']:.4f}\")\n",
    "\n",
    "# Save final results\n",
    "final_results_summary = {\n",
    "    'test_loss': final_results['total_loss'],\n",
    "    'brand_accuracy': final_results['brand_accuracy'],\n",
    "    'brand_top5_accuracy': final_results['brand_top5_accuracy'],\n",
    "    'model_accuracy': final_results['model_accuracy'],\n",
    "    'model_top5_accuracy': final_results['model_top5_accuracy'],\n",
    "    'year_accuracy': final_results['year_accuracy'],\n",
    "    'epoch': checkpoint['epoch']\n",
    "}\n",
    "\n",
    "with open(results_dir / 'final_results.json', 'w') as f:\n",
    "    json.dump(final_results_summary, f, indent=2)\n",
    "\n",
    "print(f\"\\nFinal results saved to: {results_dir / 'final_results.json'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efd3156",
   "metadata": {},
   "source": [
    "## 11. Performance Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c282727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create performance summary visualization\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 6))\n",
    "\n",
    "tasks = ['Brand', 'Model', 'Year']\n",
    "top1_accuracies = [\n",
    "    final_results['brand_accuracy'],\n",
    "    final_results['model_accuracy'],\n",
    "    final_results['year_accuracy']\n",
    "]\n",
    "\n",
    "x = np.arange(len(tasks))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax.bar(x - width/2, top1_accuracies, width, label='Top-1 Accuracy', \n",
    "               color='steelblue', alpha=0.8)\n",
    "\n",
    "# Add Top-5 for brand and model\n",
    "top5_accuracies = [\n",
    "    final_results['brand_top5_accuracy'],\n",
    "    final_results['model_top5_accuracy'],\n",
    "    0  # Year doesn't have top-5\n",
    "]\n",
    "bars2 = ax.bar(x + width/2, top5_accuracies, width, label='Top-5 Accuracy', \n",
    "               color='coral', alpha=0.8)\n",
    "\n",
    "ax.set_ylabel('Accuracy (%)', fontsize=12)\n",
    "ax.set_title('Final Test Set Performance by Task', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(tasks, fontsize=12)\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "ax.set_ylim(0, 100)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        if height > 0:\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                   f'{height:.1f}%',\n",
    "                   ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(results_dir / 'final_performance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nPerformance visualization saved to: {results_dir / 'final_performance.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53980b19",
   "metadata": {},
   "source": [
    "## 12. Model Inference Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeab8539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example inference on a batch of test images\n",
    "def predict_car(model, image_tensor, dataset, device):\n",
    "    \"\"\"\n",
    "    Predict car attributes from an image.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained model\n",
    "        image_tensor: Preprocessed image tensor\n",
    "        dataset: Dataset object for label mapping\n",
    "        device: Device to run inference on\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with predictions\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        image_tensor = image_tensor.unsqueeze(0).to(device)\n",
    "        brand_out, model_out, year_out = model(image_tensor)\n",
    "        \n",
    "        # Get predictions\n",
    "        brand_pred = brand_out.argmax(dim=1).item()\n",
    "        model_pred = model_out.argmax(dim=1).item()\n",
    "        year_pred = year_out.argmax(dim=1).item()\n",
    "        \n",
    "        # Get confidence scores\n",
    "        brand_conf = torch.softmax(brand_out, dim=1).max().item()\n",
    "        model_conf = torch.softmax(model_out, dim=1).max().item()\n",
    "        year_conf = torch.softmax(year_out, dim=1).max().item()\n",
    "        \n",
    "        # Map to labels\n",
    "        brand_name = dataset.unique_brands[brand_pred]\n",
    "        model_name = dataset.unique_models[model_pred]\n",
    "        year_value = dataset.unique_years[year_pred]\n",
    "        \n",
    "        return {\n",
    "            'brand': brand_name,\n",
    "            'brand_confidence': brand_conf,\n",
    "            'model': model_name,\n",
    "            'model_confidence': model_conf,\n",
    "            'year': year_value,\n",
    "            'year_confidence': year_conf\n",
    "        }\n",
    "\n",
    "# Test on a few samples\n",
    "print(\"Sample Predictions:\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "sample_images, sample_labels = next(iter(test_loader))\n",
    "num_samples = min(5, len(sample_images))\n",
    "\n",
    "for i in range(num_samples):\n",
    "    predictions = predict_car(model, sample_images[i], test_dataset, device)\n",
    "    \n",
    "    actual_brand = sample_labels['brand_name'][i]\n",
    "    actual_model = sample_labels['model_name'][i]\n",
    "    actual_year = sample_labels['year_value'][i]\n",
    "    \n",
    "    print(f\"\\nSample {i+1}:\")\n",
    "    print(f\"  Predicted: {predictions['brand']} {predictions['model']} ({predictions['year']})\")\n",
    "    print(f\"  Actual:    {actual_brand} {actual_model} ({actual_year})\")\n",
    "    print(f\"  Confidence: Brand={predictions['brand_confidence']:.2%}, \"\n",
    "          f\"Model={predictions['model_confidence']:.2%}, \"\n",
    "          f\"Year={predictions['year_confidence']:.2%}\")\n",
    "    \n",
    "    # Check if correct\n",
    "    brand_correct = predictions['brand'] == actual_brand\n",
    "    model_correct = predictions['model'] == actual_model\n",
    "    year_correct = predictions['year'] == actual_year\n",
    "    \n",
    "    if brand_correct and model_correct and year_correct:\n",
    "        print(\"  ✓ All predictions CORRECT!\")\n",
    "    else:\n",
    "        status = []\n",
    "        if not brand_correct:\n",
    "            status.append(\"Brand\")\n",
    "        if not model_correct:\n",
    "            status.append(\"Model\")\n",
    "        if not year_correct:\n",
    "            status.append(\"Year\")\n",
    "        print(f\"  ✗ Incorrect: {', '.join(status)}\")\n",
    "    print(\"-\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
